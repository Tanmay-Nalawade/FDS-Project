{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fake News Corpus...\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Load Fake News Corpus -----------------\n",
    "print(\"Loading Fake News Corpus...\")\n",
    "fake_news_corpus = pd.read_csv(\"../data/news_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "fake_news_corpus = fake_news_corpus[['title', 'content', 'authors', 'keywords', 'url']]\n",
    "\n",
    "# Rename columns for consistency\n",
    "fake_news_corpus.rename(columns={'authors': 'author'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize news based on source\n",
    "def categorize_source(source):\n",
    "    if source == \"opensources\":\n",
    "        return \"Fake\"\n",
    "    elif source == \"nytimes\":\n",
    "        return \"Real\"\n",
    "    else:  # webhose or other sources\n",
    "        return \"Unverified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_corpus[\"category\"] = fake_news_corpus[\"url\"].apply(categorize_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake News\n",
    "fake_kaggle = pd.read_csv(\"../data/Fake.csv\")\n",
    "fake_kaggle[\"category\"] = \"Fake\"\n",
    "\n",
    "# Real News\n",
    "real_kaggle = pd.read_csv(\"../data/True.csv\")\n",
    "real_kaggle[\"category\"] = \"Real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both Fake and Real datasets from Kaggle\n",
    "kaggle_data = pd.concat([fake_kaggle, real_kaggle], ignore_index=True)\n",
    "kaggle_data = kaggle_data[['title', 'text', 'category']]\n",
    "kaggle_data.rename(columns={'text': 'content'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing author field with \"Unknown\"\n",
    "kaggle_data[\"author\"] = \"Unknown\"\n",
    "kaggle_data[\"keywords\"] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging datasets...\")\n",
    "\n",
    "final_data = pd.concat([fake_news_corpus, kaggle_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting additional features...\")\n",
    "\n",
    "# Article Length (word count)\n",
    "final_data[\"article_length\"] = final_data[\"content\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of Keywords\n",
    "final_data[\"num_keywords\"] = final_data[\"keywords\"].apply(lambda x: len(str(x).split(',')) if x != \"Unknown\" else 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
